from keras.layers.advanced_activations import LeakyReLU
from keras.models import Model, Sequential
from keras.layers import Dense, Input,Lambda, Merge
from keras.layers.core import Flatten,Reshape
from keras.layers.normalization import BatchNormalization
from keras.layers.convolutional import Convolution2D, Deconvolution2D
from keras import initializations
from keras import backend as K
import numpy

def gaussian(shape, name=None,dim_ordering=None):
    return initializations.normal(shape, scale=0.02, name=name)

def generator_model(input_dim):
    '''
    Taking uniformly distributed random vectors as input, and generating
    64x64 images to confuse the discriminator. All the structures are the
    same as the one mentioned in the DCGan paper.
    '''

    generator = Sequential()

    # FC Layer
    generator.add(Dense(1024 * 4 * 4, input_shape = (input_dim,), activation = 'relu', init = gaussian))

    # Reshape the vector to a 4-d tensor (Batch dimension is omitted)
    generator.add(Reshape((4, 4, 1024)))
    generator.add(BatchNormalization())

    # Transpose convolution layer 1, (batch, 4, 4, 1024) -> (batch, 8, 8, 512)
    generator.add(Deconvolution2D(512, 5, 5,
                        subsample = (1,1),
                        activation = 'relu',
                        init = gaussian,
                        output_shape=(None, 8, 8, 512)))
    generator.add(BatchNormalization())

    # Transpose convolution layer 2, (batch, 8, 8, 512) -> (batch, 16, 16, 256)
    generator.add(Deconvolution2D(256,5,5,
                        subsample = (2,2),
                        activation = 'relu',
                        init = gaussian,
                        border_mode = 'same',
                        output_shape = (None, 16, 16, 256)))
    generator.add(BatchNormalization())

    # Transpose convolution layer 3, (batch, 16, 16, 256) -> (batch, 32, 32, 128)
    generator.add(Deconvolution2D(128,5,5,
                        subsample = (2,2),
                        activation = 'relu',
                        init = gaussian,
                        border_mode = 'same',
                        output_shape = (None, 32, 32, 128)))
    generator.add(BatchNormalization())

    # Transpose convolution layer 4, (batch, 32, 32, 128) -> (batch, 64, 64, 3)
    generator.add(Deconvolution2D(3,5,5,
                        subsample = (2,2),
                        activation = 'tanh',
                        init = gaussian,
                        border_mode = 'same',
                        output_shape = (None, 64, 64, 3)))

    return generator


def discriminator_model():
    '''
    The discriminator takes an image, sampled from the dataset or generated by
    the generator, as input, and outputs the probability if the input is a real
    sample in the dataset.
    '''

    discriminator = Sequential()

    # Convolution layer 1, no BatchNorm according to the paper
    discriminator.add(Convolution2D(64,5,5,
                          input_shape = (64,64,3),
                          border_mode = 'same',
                          subsample = (2,2),
                          init = gaussian))
    discriminator.add(LeakyReLU(alpha = 0.2))

    # Convolution layer 2
    discriminator.add(Convolution2D(128,5,5,
                          border_mode = 'same',
                          subsample = (2,2),
                          init = gaussian))
    discriminator.add(LeakyReLU(alpha = 0.2))
    discriminator.add(BatchNormalization())

    # Convolution layer 3
    discriminator.add(Convolution2D(256,5,5,
                          border_mode = 'same',
                          subsample = (2,2),
                          init = gaussian))
    discriminator.add(LeakyReLU(alpha = 0.2))
    discriminator.add(BatchNormalization())

    # Convolution layer 4
    discriminator.add(Convolution2D(512,5,5,
                          border_mode = 'same',
                          subsample = (2,2),
                          init = gaussian))
    discriminator.add(LeakyReLU(alpha = 0.2))
    discriminator.add(BatchNormalization())

    # Flatten the convolution output, feed it into fc layer
    discriminator.add(Flatten())
    discriminator.add(Dense(1,init = gaussian, activation = 'sigmoid'))

    return discriminator

def train_DCGan(generator, discriminator):
    image_sample = Sequential()
    image_sample.add(Lambda(lambda x:x, input_shape = (64,64,3)))
    stacked_input = Merge([image_sample , generator], mode = 'concat',concat_axis = 0)
    model = Sequential()
    model.add(stacked_input)
    model.add(discriminator)
    return model


class DCGan():

    def __init__(self, Z_dim, data, batch_size = 128, k = 5):
        self.z_dim = Z_dim
        self.data = data
        self.batch_size = batch_size
        self.k = k

        self.generator = generator_model(self.z_dim)
        self.discriminator = discriminator_model()

        # self.train_model = train_DCGan(self.generator, self.discriminator)
        # self.train_model.summary()

        self.freeze_dist()
        self.discriminator.compile('sgd','binary_crossentropy')

        # self.test_model = Sequential()
        # self.test_model.add(self.generator)
        # self.test_model.add(self.discriminator)
        # self.test_model.compile('sgd','binary_crossentropy')
        # self.test_model.summary()



    def freeze_dist(self):
        self.discriminator.trainable = False
        for layer in self.discriminator.layers:
            layer.trainable = False


    # def fit(self):




    def update_discriminator(self):
        Z = np.random.rand(self.batch_size, self.z_dim) * 2 - 1
        fake_x = self.generate(Z)
        x = self.data[np.random.permutation(self.data.shape[0])[:self.batch_size]]
        x_input = np.vstack([fake_x, x])
        y_predict = self.discriminator(x_input)
        y_label = np.hstack([np.zeros(self.batch_size), np.ones(self.batch_size)])

    def generate(self,z):
        return self.generator.fit(z)

    def discriminate(self,x_in):
        return self.discriminator.fit(x_in)
